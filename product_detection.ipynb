{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From /home/skete/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\nInstructions for updating:\nnon-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.compat.v1 as tf\n",
    "from matplotlib.pyplot import imshow\n",
    "from cv2 import imread, resize, imwrite\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "IM_EXTENSIONS = ['png', 'jpg', 'bmp', 'JPG']\n",
    "ROOT_PATH = \"../GroceryDataset_part1\"\n",
    "ROOT_TRAIN_PATH = os.path.join(ROOT_PATH, \"ShelfImages\", \"train\")\n",
    "ROOT_TEST_PATH = os.path.join(ROOT_PATH, \"ShelfImages\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(json_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def get_best_anchor(anchors, box_wh):\n",
    "    box_wh = np.array(box_wh)\n",
    "    best_iou = 0\n",
    "    best_anchor = 0\n",
    "    for k, anchor in enumerate(anchors):\n",
    "        intersect_wh = np.maximum(np.minimum(box_wh, anchor), 0.0)\n",
    "        intersect_area = intersect_wh[0] * intersect_wh[1]\n",
    "        box_area = box_wh[0] * box_wh[1]\n",
    "        anchor_area = anchor[0] * anchor[1]\n",
    "        # iou  = Intersection Over Union\n",
    "        iou = intersect_area / (box_area + anchor_area - intersect_area)\n",
    "        if iou > best_iou:\n",
    "            best_iou = iou\n",
    "            best_anchor = k\n",
    "    return best_anchor\n",
    "\n",
    "def update_bbox(img_path, bboxes):\n",
    "    img = load_img(img_path)\n",
    "    w, h = img.size\n",
    "    new_bbox = []\n",
    "    for bbox in bboxes:\n",
    "        x1, x2 = bbox[0], bbox[0]+bbox[2]\n",
    "        y1, y2 = bbox[1], bbox[1]+bbox[3]\n",
    "        new_bbox.append([x1, y1, x2, y2])\n",
    "    return new_bbox, (w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_ANNOTATIAONS = []\n",
    "TEST_ANNOTATIONS = []\n",
    "\n",
    "with open(os.path.join(ROOT_PATH, \"annotation.txt\")) as f:\n",
    "    for line in f.readlines():\n",
    "        a = line.split()\n",
    "        bboxes = []\n",
    "        for i in range(int(a[1])):\n",
    "            bboxes.append([int(j) for j in a[i*5 + 2: i*5+6]])\n",
    "        img = {}\n",
    "        if os.path.exists(os.path.join(ROOT_TRAIN_PATH, a[0])):\n",
    "            img['filename'] = os.path.join(ROOT_TRAIN_PATH, a[0])\n",
    "            bb, shape = update_bbox(os.path.join(ROOT_TRAIN_PATH, a[0]), bboxes)\n",
    "            img['width'] = shape[0]\n",
    "            img['height'] = shape[1]\n",
    "            img['object'] = []\n",
    "            for b in bb:\n",
    "                obj = {}\n",
    "                obj['name'] = \"pack\"\n",
    "                obj['xmin'], obj['ymin'], obj['xmax'], obj['ymax'] = b\n",
    "                img['object'] += [obj]\n",
    "\n",
    "            TRAIN_ANNOTATIAONS += [img]\n",
    "        if os.path.exists(os.path.join(ROOT_TEST_PATH, a[0])):\n",
    "            img['filename'] = os.path.join(ROOT_TEST_PATH, a[0])\n",
    "            bb, shape = update_bbox(os.path.join(ROOT_TEST_PATH, a[0]), bboxes)\n",
    "            img['width'] = shape[0]\n",
    "            img['height'] = shape[1]\n",
    "            img['object'] = []\n",
    "            for b in bb:\n",
    "                obj = {}\n",
    "                obj['name'] = \"pack\"\n",
    "                obj['xmin'], obj['ymin'], obj['xmax'], obj['ymax'] = b\n",
    "                img['object'] += [obj]\n",
    "\n",
    "            TEST_ANNOTATIONS += [img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(b1, b2):\n",
    "    l1, l2 = b1[0] - int(0.5 * b1[2]), b2[0] - int(0.5 * b2[2])\n",
    "    u1, u2 = l1 + b1[2] - 1, l2 + b2[2] - 1\n",
    "    intersection_w = max(0, min(u1, u2) - max(l1, l2) + 1)\n",
    "    if intersection_w == 0:\n",
    "        return 0\n",
    "    l1, l2 = b1[1] - int(0.5 * b1[3]), b2[1] - int(0.5 * b2[3])\n",
    "    u1, u2 = l1 + b1[3] - 1, l2 + b2[3] - 1\n",
    "    intersection_h = max(0, min(u1, u2) - max(l1, l2) + 1)\n",
    "    intersection = intersection_w * intersection_h\n",
    "    if intersection == 0:\n",
    "        return 0\n",
    "    union = b1[2] * b1[3] + b2[2] * b2[3] - intersection\n",
    "    if union == 0:\n",
    "        raise ValueError('Union value must not be a zero or negative number. (boxes: {}, {})'.format(b1, b2))\n",
    "    return intersection / union\n",
    "\n",
    "def kmeans_iou(boxes, k, n_iter=10):\n",
    "    n_boxes = len(boxes)\n",
    "    if k > n_boxes:\n",
    "        raise ValueError('k({}) must be less than or equal to the number of boxes({}).'.format(k, n_boxes))\n",
    "    centroids = boxes[np.random.choice(n_boxes, k, replace=False)]\n",
    "    for _ in range(n_iter):\n",
    "        cluster_indices = np.array([np.argmax([iou(b, c) for c in centroids]) for b in boxes])\n",
    "        for i in range(k):\n",
    "            if np.count_nonzero(cluster_indices == i) == 0:\n",
    "                print(i)\n",
    "        centroids = [np.mean(boxes[cluster_indices == i], axis=0) for i in range(k)]\n",
    "    return np.array(centroids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = []\n",
    "for annots in TRAIN_ANNOTATIAONS:\n",
    "    for obj in annots['object']:\n",
    "        x_min, x_max, y_min, y_max = obj['xmin'], obj['xmax'], obj['ymin'], obj['ymax']\n",
    "        center_x, center_y = (x_max + x_min) * 0.5, (y_max + y_min) * 0.5\n",
    "        width, height = x_max - x_min + 1, y_max - y_min + 1\n",
    "        boxes.append([center_x, center_y, width, height])\n",
    "boxes = np.array(boxes, dtype=np.float32)\n",
    "anchors = kmeans_iou(boxes, 1, 10)[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(annotations, image_size, pixels_per_grid=32, no_label=False):\n",
    "    num_classes = 1\n",
    "    grid_h, grid_w = [image_size[i] // pixels_per_grid for i in range(2)]\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for annotes in annotations:\n",
    "        im_path = annotes['filename']\n",
    "        # load image and resize image\n",
    "        im = imread(im_path)\n",
    "        im = np.array(im, dtype=np.float32)\n",
    "        im_origina_sizes = im.shape[:2]\n",
    "        im = resize(im, (image_size[1], image_size[0]))\n",
    "        if len(im.shape) == 2:\n",
    "            im = np.expand_dims(im, 2)\n",
    "            im = np.concatenate([im, im, im], -1)\n",
    "        images.append(im)\n",
    "\n",
    "        if no_label:\n",
    "            labels.append(0)\n",
    "            continue\n",
    "        label = np.zeros((grid_h, grid_w, len(anchors), 5 + num_classes))\n",
    "        for obj in annotes['object']:\n",
    "            x_min, x_max, y_min, y_max = obj['xmin'], obj['xmax'], obj['ymin'], obj['ymax']\n",
    "            oh, ow = im_origina_sizes\n",
    "\n",
    "            x_min, y_min, x_max, y_max = x_min / ow, y_min / oh, x_max / ow, y_max / oh\n",
    "            x_min, y_min, x_max, y_max = np.clip([x_min, y_min, x_max, y_max], 0, 1)\n",
    "\n",
    "            anchor_boxes = np.array(anchors) / np.array([ow, oh])\n",
    "            best_anchor = get_best_anchor(\n",
    "                anchor_boxes, [x_max - x_min, y_max - y_min])\n",
    "            cx = int(np.floor(0.5 * (x_min + x_max) * grid_w))\n",
    "            cy = int(np.floor(0.5 * (y_min + y_max) * grid_h))\n",
    "            label[cy, cx, best_anchor, 0:4] = [x_min, y_min, x_max, y_max]\n",
    "            label[cy, cx, best_anchor, 4] = 1.0\n",
    "            label[cy, cx, best_anchor, 5] = 1.0\n",
    "        labels.append(label)\n",
    "\n",
    "    X_set = np.array(images, dtype=np.float32)\n",
    "    y_set = np.array(labels, dtype=np.float32)\n",
    "\n",
    "    return X_set, y_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "IM_SIZE = (416, 416)\n",
    "NUM_CLASSES = 1\n",
    "VALID_RATIO = 0.1\n",
    "X_train, y_train = read_data(TRAIN_ANNOTATIAONS, IM_SIZE)\n",
    "X_test, y_test = read_data(TEST_ANNOTATIONS, IM_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet(object):\n",
    "\n",
    "    def __init__(self, images, labels=None):\n",
    "        if labels is not None:\n",
    "            assert images.shape[0] == labels.shape[0],\\\n",
    "                ('Number of examples mismatch, between images and labels')\n",
    "        self._num_examples = images.shape[0]\n",
    "        self._images = images\n",
    "        self._labels = labels  # NOTE: this can be None, if not given.\n",
    "        # image/label indices(can be permuted)\n",
    "        self._indices = np.arange(self._num_examples, dtype=np.uint)\n",
    "        self._reset()\n",
    "\n",
    "    def _reset(self):\n",
    "        \"\"\"Reset some variables.\"\"\"\n",
    "        self._epochs_completed = 0\n",
    "        self._index_in_epoch = 0\n",
    "\n",
    "    @property\n",
    "    def images(self):\n",
    "        return self._images\n",
    "\n",
    "    @property\n",
    "    def labels(self):\n",
    "        return self._labels\n",
    "\n",
    "    @property\n",
    "    def num_examples(self):\n",
    "        return self._num_examples\n",
    "\n",
    "    def sample_batch(self, batch_size, shuffle=True):\n",
    "        if shuffle:\n",
    "            indices = np.random.choice(self._num_examples, batch_size)\n",
    "        else:\n",
    "            indices = np.arange(batch_size)\n",
    "        batch_images = self._images[indices]\n",
    "        if self._labels is not None:\n",
    "            batch_labels = self._labels[indices]\n",
    "        else:\n",
    "            batch_labels = None\n",
    "        return batch_images, batch_labels\n",
    "\n",
    "    def next_batch(self, batch_size, shuffle=True):\n",
    "        start_index = self._index_in_epoch\n",
    "\n",
    "        # Shuffle the dataset, for the first epoch\n",
    "        if self._epochs_completed == 0 and start_index == 0 and shuffle:\n",
    "            np.random.shuffle(self._indices)\n",
    "\n",
    "        # Go to the next epoch, if current index goes beyond the total number\n",
    "        # of examples\n",
    "        if start_index + batch_size > self._num_examples:\n",
    "            # Increment the number of epochs completed\n",
    "            self._epochs_completed += 1\n",
    "            # Get the rest examples in this epoch\n",
    "            rest_num_examples = self._num_examples - start_index\n",
    "            indices_rest_part = self._indices[start_index:self._num_examples]\n",
    "\n",
    "            # Shuffle the dataset, after finishing a single epoch\n",
    "            if shuffle:\n",
    "                np.random.shuffle(self._indices)\n",
    "\n",
    "            # Start the next epoch\n",
    "            start_index = 0\n",
    "            self._index_in_epoch = batch_size - rest_num_examples\n",
    "            end_index = self._index_in_epoch\n",
    "            indices_new_part = self._indices[start_index:end_index]\n",
    "\n",
    "            images_rest_part = self._images[indices_rest_part]\n",
    "            images_new_part = self._images[indices_new_part]\n",
    "            batch_images = np.concatenate(\n",
    "                (images_rest_part, images_new_part), axis=0)\n",
    "            if self._labels is not None:\n",
    "                labels_rest_part = self._labels[indices_rest_part]\n",
    "                labels_new_part = self._labels[indices_new_part]\n",
    "                batch_labels = np.concatenate(\n",
    "                    (labels_rest_part, labels_new_part), axis=0)\n",
    "            else:\n",
    "                batch_labels = None\n",
    "        else:\n",
    "            self._index_in_epoch += batch_size\n",
    "            end_index = self._index_in_epoch\n",
    "            indices = self._indices[start_index:end_index]\n",
    "            batch_images = self._images[indices]\n",
    "            if self._labels is not None:\n",
    "                batch_labels = self._labels[indices]\n",
    "            else:\n",
    "                batch_labels = None\n",
    "\n",
    "        return batch_images, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = DataSet(X_train, y_train)\n",
    "test_set = DataSet(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(x, filters, kernel_size, strides, padding='SAME', use_bias=True, **kwargs):\n",
    "    weights_stddev = kwargs.pop('weights_stddev', 0.01)\n",
    "    return tf.layers.conv2d(\n",
    "        x,\n",
    "        filters,\n",
    "        kernel_size,\n",
    "        strides,\n",
    "        padding,\n",
    "        kernel_initializer=tf.random_normal_initializer(stddev=weights_stddev),\n",
    "        use_bias=use_bias\n",
    "    )\n",
    "\n",
    "def batchNormalization(x, is_train):\n",
    "    return tf.layers.batch_normalization(\n",
    "        x,\n",
    "        training=is_train,\n",
    "        momentum=0.99,\n",
    "        epsilon=0.001,\n",
    "        center=True,\n",
    "        scale=True\n",
    "    )\n",
    "\n",
    "def conv_bn_relu(x, filters, kernel_size, is_train, strides=(1, 1), padding='SAME', relu=True):\n",
    "    conv = conv_layer(x, filters, kernel_size, strides, padding, use_bias=False)\n",
    "    bn = batchNormalization(conv, is_train)\n",
    "    if relu:\n",
    "        return tf.nn.leaky_relu(bn, alpha=0.1)\n",
    "    else:\n",
    "        return bn\n",
    "\n",
    "def max_pool(x, side_l, stride, padding='SAME'):\n",
    "    return tf.nn.max_pool(x, ksize=[1, side_l, side_l, 1],\n",
    "                          strides=[1, stride, stride, 1], padding=padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = list(IM_SIZE) + [3]\n",
    "num_classes = NUM_CLASSES\n",
    "grid_size = [x // 32 for x in input_shape[:2]]\n",
    "num_anchors = len(anchors)\n",
    "\n",
    "# Prepare Input\n",
    "X = tf.placeholder(tf.float32, [None] + input_shape)\n",
    "y = tf.placeholder(tf.float32, [None] + grid_size + [num_anchors] + [5 + num_classes])\n",
    "is_train = tf.placeholder(tf.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.get_default_graph()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From /home/skete/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/normalization.py:534: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "/home/skete/.local/lib/python3.8/site-packages/tensorflow/python/keras/legacy_tf_layers/convolutional.py:414: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  warnings.warn('`tf.layers.conv2d` is deprecated and '\n",
      "/home/skete/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1692: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "/home/skete/.local/lib/python3.8/site-packages/tensorflow/python/keras/legacy_tf_layers/normalization.py:307: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "d = dict()\n",
    "\n",
    "#conv1 - batch_norm1 - leaky_relu1 - pool1\n",
    "with tf.variable_scope('layer1'):\n",
    "    d['conv1'] = conv_bn_relu(X, 32, (3, 3), is_train)\n",
    "    d['pool1'] = max_pool(d['conv1'], 2, 2, padding='SAME')\n",
    "# (416, 416, 3) --> (208, 208, 32)\n",
    "\n",
    "#conv2 - batch_norm2 - leaky_relu2 - pool2\n",
    "with tf.variable_scope('layer2'):\n",
    "    d['conv2'] = conv_bn_relu(d['pool1'], 64, (3, 3), is_train)\n",
    "    d['pool2'] = max_pool(d['conv2'], 2, 2, padding='SAME')\n",
    "# (208, 208, 32) --> (104, 104, 64)\n",
    "\n",
    "#conv3 - batch_norm3 - leaky_relu3\n",
    "with tf.variable_scope('layer3'):\n",
    "    d['conv3'] = conv_bn_relu(d['pool2'], 128, (3, 3), is_train)\n",
    "# (104, 104, 64) --> (104, 104, 128)\n",
    "\n",
    "#conv4 - batch_norm4 - leaky_relu4\n",
    "with tf.variable_scope('layer4'):\n",
    "    d['conv4'] = conv_bn_relu(d['conv3'], 64, (1, 1), is_train)\n",
    "# (104, 104, 128) --> (104, 104, 64)\n",
    "\n",
    "#conv5 - batch_norm5 - leaky_relu5 - pool5\n",
    "with tf.variable_scope('layer5'):\n",
    "    d['conv5'] = conv_bn_relu(d['conv4'], 128, (3, 3), is_train)\n",
    "    d['pool5'] = max_pool(d['conv5'], 2, 2, padding='SAME')\n",
    "# (104, 104, 64) --> (52, 52, 128)\n",
    "\n",
    "#conv6 - batch_norm6 - leaky_relu6\n",
    "with tf.variable_scope('layer6'):\n",
    "    d['conv6'] = conv_bn_relu(d['pool5'], 256, (3, 3), is_train)\n",
    "# (52, 52, 128) --> (52, 52, 256)\n",
    "\n",
    "#conv7 - batch_norm7 - leaky_relu7\n",
    "with tf.variable_scope('layer7'):\n",
    "    d['conv7'] = conv_bn_relu(d['conv6'], 128, (1, 1), is_train)\n",
    "# (52, 52, 256) --> (52, 52, 128)\n",
    "\n",
    "#conv8 - batch_norm8 - leaky_relu8 - pool8\n",
    "with tf.variable_scope('layer8'):\n",
    "    d['conv8'] = conv_bn_relu(d['conv7'], 256, (3, 3), is_train)\n",
    "    d['pool8'] = max_pool(d['conv8'], 2, 2, padding='SAME')\n",
    "# (52, 52, 128) --> (26, 26, 256)\n",
    "\n",
    "#conv9 - batch_norm9 - leaky_relu9\n",
    "with tf.variable_scope('layer9'):\n",
    "    d['conv9'] = conv_bn_relu(d['pool8'], 512, (3, 3), is_train)\n",
    "# (26, 26, 256) --> (26, 26, 512)\n",
    "\n",
    "#conv10 - batch_norm10 - leaky_relu10\n",
    "with tf.variable_scope('layer10'):\n",
    "    d['conv10'] = conv_bn_relu(d['conv9'], 256, (1, 1), is_train)\n",
    "# (26, 26, 512) --> (26, 26, 256)\n",
    "\n",
    "#conv11 - batch_norm11 - leaky_relu11\n",
    "with tf.variable_scope('layer11'):\n",
    "    d['conv11'] = conv_bn_relu(d['conv10'], 512, (3, 3), is_train)\n",
    "# (26, 26, 256) --> (26, 26, 512)\n",
    "\n",
    "#conv12 - batch_norm12 - leaky_relu12\n",
    "with tf.variable_scope('layer12'):\n",
    "    d['conv12'] = conv_bn_relu(d['conv11'], 256, (1, 1), is_train)\n",
    "# (26, 26, 512) --> (26, 26, 256)\n",
    "\n",
    "#conv13 - batch_norm13 - leaky_relu13 - pool13\n",
    "with tf.variable_scope('layer13'):\n",
    "    d['conv13'] = conv_bn_relu(d['conv12'], 512, (3, 3), is_train)\n",
    "    d['pool13'] = max_pool(d['conv13'], 2, 2, padding='SAME')\n",
    "# (26, 26, 256) --> (13, 13, 512)\n",
    "\n",
    "#conv14 - batch_norm14 - leaky_relu14\n",
    "with tf.variable_scope('layer14'):\n",
    "    d['conv14'] = conv_bn_relu(d['pool13'], 1024, (3, 3), is_train)\n",
    "# (13, 13, 512) --> (13, 13, 1024)\n",
    "\n",
    "#conv15 - batch_norm15 - leaky_relu15\n",
    "with tf.variable_scope('layer15'):\n",
    "    d['conv15'] = conv_bn_relu(d['conv14'], 512, (1, 1), is_train)\n",
    "# (13, 13, 1024) --> (13, 13, 512)\n",
    "\n",
    "#conv16 - batch_norm16 - leaky_relu16\n",
    "with tf.variable_scope('layer16'):\n",
    "    d['conv16'] = conv_bn_relu(d['conv15'], 1024, (3, 3), is_train)\n",
    "# (13, 13, 512) --> (13, 13, 1024)\n",
    "\n",
    "#conv17 - batch_norm16 - leaky_relu17\n",
    "with tf.variable_scope('layer17'):\n",
    "    d['conv17'] = conv_bn_relu(d['conv16'], 512, (1, 1), is_train)\n",
    "# (13, 13, 1024) --> (13, 13, 512)\n",
    "\n",
    "#conv18 - batch_norm18 - leaky_relu18\n",
    "with tf.variable_scope('layer18'):\n",
    "    d['conv18'] = conv_bn_relu(d['conv17'], 1024, (3, 3), is_train)\n",
    "# (13, 13, 512) --> (13, 13, 1024)\n",
    "\n",
    "#conv19 - batch_norm19 - leaky_relu19\n",
    "with tf.variable_scope('layer19'):\n",
    "    d['conv19'] = conv_bn_relu(d['conv18'], 1024, (3, 3), is_train)\n",
    "# (13, 13, 1024) --> (13, 13, 1024)\n",
    "\n",
    "#Detection Layer\n",
    "#conv20 - batch_norm20 - leaky_relu20\n",
    "with tf.variable_scope('layer20'):\n",
    "    d['conv20'] = conv_bn_relu(d['conv19'], 1024, (3, 3), is_train)\n",
    "# (13, 13, 1024) --> (13, 13, 1024)\n",
    "\n",
    "# concatenate layer20 and layer 13 using space to depth\n",
    "with tf.variable_scope('layer21'):\n",
    "    d['skip_connection'] = conv_bn_relu(d['conv13'], 64, (1, 1), is_train)\n",
    "    d['skip_space_to_depth_x2'] = tf.space_to_depth(\n",
    "        d['skip_connection'], block_size=2)\n",
    "    d['concat21'] = tf.concat(\n",
    "        [d['skip_space_to_depth_x2'], d['conv20']], axis=-1)\n",
    "# (13, 13, 1024) --> (13, 13, 256+1024)\n",
    "\n",
    "#conv22 - batch_norm22 - leaky_relu22\n",
    "with tf.variable_scope('layer22'):\n",
    "    d['conv22'] = conv_bn_relu(d['concat21'], 1024, (3, 3), is_train)\n",
    "# (13, 13, 1280) --> (13, 13, 1024)\n",
    "\n",
    "with tf.variable_scope('output_layer'):\n",
    "    output_channel = num_anchors * (5 + num_classes)\n",
    "    d['logits'] = conv_layer(d['conv22'], output_channel, (1, 1), (1, 1),\n",
    "                            padding='SAME', use_bias=True)\n",
    "    d['pred'] = tf.reshape(\n",
    "        d['logits'], (-1, grid_size[0], grid_size[1], num_anchors, 5 + num_classes))\n",
    "# (13, 13, 1024) --> (13, 13, num_anchors , (5 + num_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = d['logits']\n",
    "pred = d['pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_weights = [5, 5, 5, 0.5, 1.0]\n",
    "\n",
    "grid_h, grid_w = grid_size\n",
    "grid_wh = np.reshape([grid_w, grid_h], [1, 1, 1, 1, 2]).astype(np.float32)\n",
    "cxcy = np.transpose([np.tile(np.arange(grid_w), grid_h),\n",
    "                     np.repeat(np.arange(grid_h), grid_h)])\n",
    "cxcy = np.reshape(cxcy, (1, grid_h, grid_w, 1, 2))\n",
    "\n",
    "txty, twth = pred[..., 0:2], pred[..., 2:4]\n",
    "confidence = tf.sigmoid(pred[..., 4:5])\n",
    "class_probs = tf.nn.softmax(pred[..., 5:], axis=-1)            if num_classes > 1 else tf.sigmoid(pred[..., 5:])\n",
    "bxby = tf.sigmoid(txty) + cxcy\n",
    "pwph = np.reshape(anchors, (1, 1, 1, num_anchors, 2)) / 32\n",
    "bwbh = tf.exp(twth) * pwph\n",
    "\n",
    "# calculating for prediction\n",
    "nxny, nwnh = bxby / grid_wh, bwbh / grid_wh\n",
    "nx1ny1, nx2ny2 = nxny - 0.5 * nwnh, nxny + 0.5 * nwnh\n",
    "pred_y = tf.concat((nx1ny1, nx2ny2, confidence, class_probs), axis=-1)\n",
    "\n",
    "# calculating IoU for metric\n",
    "num_objects = tf.reduce_sum(y[..., 4:5], axis=[1, 2, 3, 4])\n",
    "max_nx1ny1 = tf.maximum(y[..., 0:2], nx1ny1)\n",
    "min_nx2ny2 = tf.minimum(y[..., 2:4], nx2ny2)\n",
    "intersect_wh = tf.maximum(min_nx2ny2 - max_nx1ny1, 0.0)\n",
    "intersect_area = tf.reduce_prod(intersect_wh, axis=-1)\n",
    "intersect_area = tf.where(\n",
    "    tf.equal(intersect_area, 0.0), tf.zeros_like(intersect_area), intersect_area)\n",
    "gt_box_area = tf.reduce_prod(y[..., 2:4] - y[..., 0:2], axis=-1)\n",
    "box_area = tf.reduce_prod(nx2ny2 - nx1ny1, axis=-1)\n",
    "iou = tf.truediv(intersect_area, (gt_box_area + box_area - intersect_area))\n",
    "\n",
    "gt_bxby = 0.5 * (y[..., 0:2] + y[..., 2:4]) * grid_wh\n",
    "gt_bwbh = (y[..., 2:4] - y[..., 0:2]) * grid_wh\n",
    "\n",
    "resp_mask = y[..., 4:5]\n",
    "no_resp_mask = 1.0 - resp_mask\n",
    "#gt_confidence = resp_mask * tf.expand_dims(iou, axis=-1)\n",
    "gt_confidence = resp_mask\n",
    "gt_class_probs = y[..., 5:]\n",
    "\n",
    "loss_bxby = loss_weights[0] * resp_mask * tf.square(gt_bxby - bxby)\n",
    "loss_bwbh = loss_weights[1] * resp_mask * tf.square(tf.sqrt(gt_bwbh) - tf.sqrt(bwbh))\n",
    "loss_resp_conf = loss_weights[2] * resp_mask * tf.square(gt_confidence - confidence)\n",
    "loss_no_resp_conf = loss_weights[3] * no_resp_mask * tf.square(gt_confidence - confidence)\n",
    "loss_class_probs = loss_weights[4] * resp_mask * tf.square(gt_class_probs - class_probs)\n",
    "\n",
    "merged_loss = tf.concat((\n",
    "                        loss_bxby,\n",
    "                        loss_bwbh,\n",
    "                        loss_resp_conf,\n",
    "                        loss_no_resp_conf,\n",
    "                        loss_class_probs\n",
    "                        ),\n",
    "                        axis=-1)\n",
    "total_loss = tf.reduce_sum(merged_loss, axis=-1)\n",
    "total_loss = tf.reduce_mean(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms(boxes, conf_thres=0.2, iou_thres=0.5):\n",
    "    x1 = boxes[..., 0]\n",
    "    y1 = boxes[..., 1]\n",
    "    x2 = boxes[..., 2]\n",
    "    y2 = boxes[..., 3]\n",
    "    areas = (x2 - x1) * (y2 - y1)\n",
    "    scores = boxes[..., 4]\n",
    "\n",
    "    keep = []\n",
    "    order = scores.argsort()[::-1]\n",
    "\n",
    "    while order.size > 0:\n",
    "        i = order[0]\n",
    "        keep.append(i)\n",
    "        xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "        yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "        xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "        yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "\n",
    "        w = np.maximum(0.0, xx2 - xx1)\n",
    "        h = np.maximum(0.0, yy2 - yy1)\n",
    "        inter = w * h\n",
    "        ovr = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "\n",
    "        inds = np.where(ovr <= iou_thres)[0]\n",
    "        order = order[inds + 1]\n",
    "\n",
    "    nms_box = []\n",
    "    for idx in range(len(boxes)):\n",
    "        if idx in keep and boxes[idx, 4] > conf_thres:\n",
    "            nms_box.append(boxes[idx])\n",
    "        else:\n",
    "            nms_box.append(np.zeros(boxes.shape[-1]))\n",
    "    boxes = np.array(nms_box)\n",
    "    return boxes\n",
    "\n",
    "def convert_boxes(input_y):\n",
    "    is_batch = len(input_y.shape) == 5\n",
    "    if not is_batch:\n",
    "        input_y = np.expand_dims(input_y, 0)\n",
    "    boxes = np.reshape(input_y, (input_y.shape[0], -1, input_y.shape[-1]))\n",
    "    if is_batch:\n",
    "        return np.array(boxes)\n",
    "    else:\n",
    "        return boxes[0]\n",
    "\n",
    "def predict_nms_boxes(input_y, conf_thres=0.2, iou_thres=0.5):\n",
    "    is_batch = len(input_y.shape) == 5\n",
    "    if not is_batch:\n",
    "        input_y = np.expand_dims(input_y, 0)\n",
    "    boxes = np.reshape(input_y, (input_y.shape[0], -1, input_y.shape[-1]))\n",
    "    nms_boxes = []\n",
    "    for box in boxes:\n",
    "        nms_box = nms(box, conf_thres, iou_thres)\n",
    "        nms_boxes.append(nms_box)\n",
    "    if is_batch:\n",
    "        return np.array(nms_boxes)\n",
    "    else:\n",
    "        return nms_boxes[0]\n",
    "\n",
    "def cal_map(gt_bboxes, bboxes,thresholds=[0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75]):\n",
    "    m_tot = 0.0\n",
    "    for iou_thres in thresholds:\n",
    "        p = 0\n",
    "        tp = 0\n",
    "        for idx, (gt, bbox) in enumerate(zip(gt_bboxes, bboxes)):\n",
    "            gt = gt[np.nonzero(np.any(gt > 0, axis=1))]\n",
    "            bbox = bbox[np.nonzero(np.any(bbox > 0, axis=1))]\n",
    "            p += len(gt)\n",
    "            if bbox.size == 0:\n",
    "                continue\n",
    "            iou = _cal_overlap(gt, bbox)\n",
    "            predicted_class = np.argmax(bbox[...,5:], axis=-1)\n",
    "            for g, area in zip(gt, iou):\n",
    "                gt_c = np.argmax(g[5:])\n",
    "                idx = np.argmax(area)\n",
    "                if np.max(area) > iou_thres and predicted_class[idx] == gt_c:\n",
    "                    tp += 1\n",
    "        m = tp / p\n",
    "        m_tot+=m\n",
    "    return m_tot/len(thresholds)\n",
    "\n",
    "def cal_recall(gt_bboxes, bboxes,iou_thres):\n",
    "    tp = 0\n",
    "    n = 0\n",
    "    for idx, (gt, bbox) in enumerate(zip(gt_bboxes, bboxes)):\n",
    "        gt = gt[np.nonzero(np.any(gt > 0, axis=1))]\n",
    "        bbox = bbox[np.nonzero(np.any(bbox > 0, axis=1))]\n",
    "        n += len(bbox)\n",
    "        if bbox.size == 0:\n",
    "            continue\n",
    "        iou = _cal_overlap(gt, bbox)\n",
    "        predicted_class = np.argmax(bbox[...,5:], axis=-1)\n",
    "        for g, area in zip(gt, iou):\n",
    "            gt_c = np.argmax(g[5:])\n",
    "            idx = np.argmax(area)\n",
    "            if np.max(area) > iou_thres and predicted_class[idx] == gt_c:\n",
    "                tp += 1\n",
    "    m = tp / n\n",
    "    return m\n",
    "\n",
    "def _cal_overlap(a, b):\n",
    "    area = (b[:, 2] - b[:, 0]) * (b[:, 3] - b[:, 1])\n",
    "    iw = np.minimum(np.expand_dims(a[:, 2], axis=1), b[:, 2]) - np.maximum(np.expand_dims(a[:, 0], axis=1), b[:, 0])\n",
    "    ih = np.minimum(np.expand_dims(a[:, 3], axis=1), b[:, 3]) - np.maximum(np.expand_dims(a[:, 1], axis=1), b[:, 1])\n",
    "    iw = np.maximum(iw, 0)\n",
    "    ih = np.maximum(ih, 0)\n",
    "    intersection = iw * ih\n",
    "    ua = np.expand_dims((a[:, 2] - a[:, 0]) * (a[:, 3] - a[:, 1]), axis=1) + area - intersection\n",
    "    ua = np.maximum(ua, np.finfo(float).eps)\n",
    "    return intersection / ua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(y_true, y_pred, **kwargs):\n",
    "    \"\"\"Compute Recall for a given predicted bboxes\"\"\"\n",
    "    nms_flag = kwargs.pop('nms_flag', True)\n",
    "    if nms_flag:\n",
    "        bboxes = predict_nms_boxes(y_pred)\n",
    "    else:\n",
    "        bboxes = convert_boxes(y_pred)\n",
    "    gt_bboxes = convert_boxes(y_true)\n",
    "    score = cal_map(gt_bboxes, bboxes)\n",
    "    return score\n",
    "\n",
    "def predict(sess, dataset, **kwargs):\n",
    "    batch_size = kwargs.pop('batch_size', 16)\n",
    "    pred_size = dataset.num_examples\n",
    "    num_steps = pred_size // batch_size\n",
    "    flag = int(bool(pred_size % batch_size))\n",
    "    # Start prediction loop\n",
    "    _y_pred = []\n",
    "    for i in range(num_steps + flag):\n",
    "        if i == num_steps and flag:\n",
    "            _batch_size = pred_size - num_steps * batch_size\n",
    "        else:\n",
    "            _batch_size = batch_size\n",
    "        X_true, _ = dataset.next_batch(_batch_size, shuffle=False)\n",
    "\n",
    "        # Compute predictions\n",
    "        y_pred = sess.run(pred_y, feed_dict={\n",
    "                          X: X_true, is_train: False})\n",
    "\n",
    "        _y_pred.append(y_pred)\n",
    "    _y_pred = np.concatenate(_y_pred, axis=0)\n",
    "    return _y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session(graph=graph, config=config)\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "num_epochs = 100\n",
    "learning_rate = 1e-4\n",
    "eps = 1e-3\n",
    "num_eval = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "update_vars = tf.trainable_variables()\n",
    "with tf.control_dependencies(extra_update_ops):\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(total_loss, var_list=update_vars)\n",
    "    \n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = train_set.num_examples\n",
    "num_steps_per_epoch = train_size // batch_size\n",
    "num_steps = num_epochs * num_steps_per_epoch\n",
    "curr_epoch = 1\n",
    "best_score = 0\n",
    "curr_score = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT THE BELOW LINES ONLY IF YOU WANT TO TRAIN\n",
    "\n",
    "## Start training loop\n",
    "\n",
    "# for i in range(num_steps):\n",
    "#     X_true, y_true = train_set.next_batch(batch_size, shuffle=True)\n",
    "#     _, loss, y_pred = sess.run([train_op, total_loss, pred_y],\n",
    "#                               feed_dict={X:X_true, y: y_true, is_train: True})\n",
    "#     if (i+1) % num_eval == 0:\n",
    "#         step_score = score(y_true, y_pred)\n",
    "#         eval_y_pred = predict(sess, test_set)\n",
    "#         eval_score = score(test_set.labels, eval_y_pred)\n",
    "#         print('[epoch {}]\\tloss: {:.6f} |Train score: {:.6f} |Eval score: {:.6f}'\n",
    "#       .format(curr_epoch, loss, step_score, eval_score))\n",
    "#         curr_score = eval_score\n",
    "\n",
    "#     if curr_score > best_score + eps:\n",
    "#         best_score = curr_score\n",
    "#         saver.save(sess, './yolov2.ckpt')\n",
    "\n",
    "#     if (i+1) % num_steps_per_epoch == 0:\n",
    "#         curr_epoch += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./yolov2.ckpt\n"
     ]
    }
   ],
   "source": [
    "saver.restore(sess, './yolov2.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING\n",
    "\n",
    "test_y_pred = predict(sess, test_set)\n",
    "test_score = score(test_set.labels, test_y_pred)\n",
    "mAP = test_score\n",
    "test_bboxes = predict_nms_boxes(test_y_pred)\n",
    "gt_test_bboxes = convert_boxes(test_set.labels)\n",
    "precision = cal_map(test_bboxes, gt_test_bboxes, thresholds=[0.5])\n",
    "recall = cal_recall(test_bboxes, gt_test_bboxes, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {}\n",
    "for images, annot in zip(test_set.images, TEST_ANNOTATIONS):\n",
    "    test_pred_y = sess.run(pred_y, feed_dict={X: [images], is_train: False})\n",
    "    bboxes = predict_nms_boxes(test_pred_y[0], conf_thres=0.5, iou_thres=0.5)\n",
    "    bboxes = bboxes[np.nonzero(np.any(bboxes > 0, axis=1))]\n",
    "    results_dict[annot['filename'].split('/')[-1]] = bboxes.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    \"mAP\" : mAP,\n",
    "    \"precision\": precision,\n",
    "    \"recall\": recall\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"metrics.json\", \"w\") as f:\n",
    "    json.dump(metrics, f)\n",
    "with open(\"image2products.json\", \"w\") as f:\n",
    "    json.dump(results_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}